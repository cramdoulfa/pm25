{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from src.sample_tiles import *\n",
    "import pandas as pd\n",
    "\n",
    "from src.tilenet import make_tilenet\n",
    "from src.resnet import ResNet18\n",
    "import torch\n",
    "from time import time\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Place a few images of low pollution season in '../data.nosync/planet-lab-images/low/', same for high.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir_path = '../data.nosync/planet-lab-images/'\n",
    "tile_dir_path = '../data.nosync/planet-lab-tiles/'\n",
    "\n",
    "im_dir_low = im_dir_path + 'low/'\n",
    "im_dir_high = im_dir_path + 'high/'\n",
    "tiles_dir_low = tile_dir_path + 'low/'\n",
    "tiles_dir_high = tile_dir_path + 'high/'\n",
    "\n",
    "low_high_dict = {im_dir_low: tile_dir_low,\n",
    "                 im_dir_high: tile_dir_high}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dir, tile_dir in low_high_dict.items():\n",
    "    try:\n",
    "        os.remove(os.path.join(tile_dir, '.DS_Store'))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.remove(os.path.join(img_dir, '.DS_Store'))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a random inage from the im_dir_high\n",
    "# if it picks .DS_Store, try again or remove that file\n",
    "\n",
    "img_file = im_dir_high + random.sample(os.listdir(im_dir_high), 1)[0]\n",
    "\n",
    "with rasterio.open(img_file) as src:\n",
    "    profile = src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a padding to get coodinates for the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = load_img(img_file, val_type='uint16', bands_only=False)\n",
    "\n",
    "\n",
    "img_padded = np.pad(img_data, pad_width=[(tile_radius, tile_radius),\n",
    "                                             (tile_radius, tile_radius), \n",
    "                                             (0,0)],\n",
    "                        mode='reflect')\n",
    "img_shape = img_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a tile form that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sample_anchor(img_shape, tile_radius)\n",
    "tile = extract_tile(img_padded, x, y, tile_radius)\n",
    "tile = tile[:-1,:-1] # see size_even\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need tile_size = 50 to feel into the CNN but can use a bigger one to visualize\n",
    "tile_size=1000\n",
    "tile_radius = tile_size // 2\n",
    "\n",
    "x, y = sample_anchor(img_shape, tile_radius)\n",
    "tile = extract_tile(img_padded, x, y, tile_radius)\n",
    "tile = tile[:-1,:-1] # see size_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tile[:,:,[3,2,1]] / 10000.0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can play with the settings, still not sure which is the right one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to sample a couple thousand tiles from low pollution days and a couple thousand from high polution.\n",
    "\n",
    "The cell below will extract tiles_per_image tiles for each image present in img_dir directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_per_image = 500\n",
    "tile_size=50\n",
    "tile_radius = tile_size // 2\n",
    "\n",
    "for img_dir, tile_dir in low_high_dict.items():\n",
    "\n",
    "    for image in os.listdir(img_dir):\n",
    "        print('Saving tiles for ', image, ' in ', tile_dir)\n",
    "        img = load_img(os.path.join(img_dir, image), val_type='uint16', bands_only=True)\n",
    "        img_padded = np.pad(img, pad_width=[(tile_radius, tile_radius),\n",
    "                                            (tile_radius, tile_radius), \n",
    "                                            (0,0)],\n",
    "                            mode='reflect')\n",
    "        img_shape = img_padded.shape\n",
    "\n",
    "        for i in range(tiles_per_image):\n",
    "            x, y = sample_anchor(img_shape, tile_radius)\n",
    "            tile = extract_tile(img_padded, x, y, tile_radius)\n",
    "            tile = tile[:-1,:-1] # see size_even\n",
    "            tile = tile[:,:,[3,2,1,0]] / 10000.0\n",
    "            np.save(os.path.join(tile_dir, 'planet_tile_' + image[4:15] + '_{}.npy'.format(i)), tile)\n",
    "            i = i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "in_channels = 4\n",
    "z_dim = 512\n",
    "cuda = torch.cuda.is_available()\n",
    "# tilenet = make_tilenet(in_channels=in_channels, z_dim=z_dim)\n",
    "# Use old model for now\n",
    "tilenet = ResNet18()\n",
    "if cuda: tilenet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "model_fn = '../models/naip_trained.ckpt'\n",
    "checkpoint = torch.load(model_fn, map_location='cpu')\n",
    "tilenet.load_state_dict(checkpoint)\n",
    "tilenet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some of the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_dir = tile_dir_low\n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "n_tile_plot = 10\n",
    "\n",
    "for img_dir, tile_dir in low_high_dict.items():\n",
    "    i = 0\n",
    "    for filename in random.sample(os.listdir(tile_dir), n_tile_plot):\n",
    "        tile = np.load(os.path.join(tile_dir, filename))\n",
    "        print('Tile ' + filename)\n",
    "        plt.imshow(tile[:,:,[0,1,2]])\n",
    "        i +=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Black Tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiles that are sampled in the black area are all black, and have a close to zero mean for all their values. We remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_dir, tile_dir in low_high_dict.items():\n",
    "    filenames = os.listdir(tile_dir)\n",
    "    before = len(filenames)\n",
    "    for filename in filenames:\n",
    "        tile = np.load(os.path.join(tile_dir, filename))\n",
    "        if tile.mean() < 0.01:\n",
    "            os.remove(os.path.join(tile_dir, filename))\n",
    "    filenames = os.listdir(tile_dir)\n",
    "    print('Removed ', before - len(os.listdir(tile_dir)), ' black tiles from ', tile_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embbed Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the features table for low and high PM25 samples\n",
    "\n",
    "# instanciate\n",
    "X_low = np.zeros((1, z_dim))\n",
    "X_high = np.zeros((1, z_dim))\n",
    "X_dict = {tile_dir_low: X_low,\n",
    "          tile_dir_high: X_high}\n",
    "\n",
    "# loop over all tiles and calculate embedding. It takes about 1 min for 500 tiles on my computer, so take it easy\n",
    "for tile_dir, X in X_dict.items():\n",
    "    print('Parsing ', tile_dir)\n",
    "    n_tiles = len(os.listdir(tile_dir))\n",
    "    X = np.zeros((n_tiles, z_dim))\n",
    "    # Embed tiles\n",
    "    t0 = time()\n",
    "    i = 0\n",
    "    for filename in os.listdir(tile_dir):\n",
    "        while i < n_tiles:\n",
    "            tile = np.load(os.path.join(tile_dir, filename))\n",
    "            # Get first 4 NAIP channels (5th is CDL mask)\n",
    "            tile = tile[:,:,:4]\n",
    "            # Rearrange to PyTorch order\n",
    "            tile = np.moveaxis(tile, -1, 0)\n",
    "            tile = np.expand_dims(tile, axis=0)\n",
    "            # Scale to [0, 1]\n",
    "            tile = tile / 255\n",
    "            # Embed tile\n",
    "            tile = torch.from_numpy(tile).float()\n",
    "            tile = Variable(tile)\n",
    "            if cuda: tile = tile.cuda()\n",
    "            z = tilenet.encode(tile)\n",
    "            if cuda: z = z.cpu()\n",
    "            z = z.data.numpy()\n",
    "            X[i,:] = z\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print(i, ' / ', n_tiles)\n",
    "        t1 = time()\n",
    "    X_dict[tile_dir] = X\n",
    "    print('Embedded {} tiles: {:0.3f}s'.format(n_tiles, t1-t0))\n",
    "    print('Features table shape : ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Features Datatable and get labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = pd.DataFrame(X_dict[tile_dir_high])\n",
    "df_high['label'] = 1\n",
    "\n",
    "df_low = pd.DataFrame(X_dict[tile_dir_high])\n",
    "df_low['label'] = 0\n",
    "\n",
    "\n",
    "features = pd.concat([df_high, df_low], axis = 0)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reset_index()\n",
    "labels = features['label']\n",
    "features = features.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low VS High Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a grid search that tries to find optimal hypoerparameters on different model. You can also do it more 'by-hand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.30\n",
    "\n",
    "random_state = 13\n",
    "held_out_size = 0.3\n",
    "n_splits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "             features, \n",
    "             labels, \n",
    "             test_size=test_size,\n",
    "             shuffle = True,\n",
    "             random_state = random_state)\n",
    "    \n",
    "kfold = KFold(n_splits = 3,              \n",
    "              random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_models = [LogisticRegression(solver = 'liblinear'),\n",
    "                 DecisionTreeClassifier(),\n",
    "                 KNeighborsClassifier(),\n",
    "                 RandomForestClassifier(random_state = random_state, n_estimators = 33),\n",
    "                 MLPClassifier(learning_rate='adaptive', learning_rate_init = 0.1, random_state = random_state),\n",
    "                 MLPClassifier(learning_rate='adaptive', learning_rate_init = 0.1, random_state = random_state)]\n",
    "\n",
    "parameterScope = [{'penalty' : ['l1', 'l2'], 'C' :  [000.1, 0.005, 0.01, 0.1]},\n",
    "                  {'min_samples_leaf' : list(range(5, 100, 45))},\n",
    "                  {'n_neighbors' : list(range(10, 100, 10))},\n",
    "                  {'max_depth' : list(range(2, 10, 2)), \n",
    "                   'n_estimators' : range(20, 85, 30)}]\n",
    "\n",
    "binary_names = ['Logistic Regression',\n",
    "                'Decision Tree',\n",
    "                'K-Nearest Neighbors',\n",
    "                'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_binary_models = []\n",
    "performance = pd.Series()\n",
    "bestParam = pd.Series()\n",
    "\n",
    "\n",
    "for model, parameters, name in zip(binary_models, parameterScope, binary_names):\n",
    "    parameterEstimator = GridSearchCV(model, parameters, cv = kfold, refit = True, return_train_score=False)\n",
    "    parameterEstimator.fit(X_train, y_train)\n",
    "    performance[name] = parameterEstimator.best_score_\n",
    "    bestParam[name] = parameterEstimator.best_params_\n",
    "    print(name)\n",
    "    print(performance[name])\n",
    "    print(bestParam[name])\n",
    "    fitted_binary_models.append(parameterEstimator.best_estimator_)\n",
    "\n",
    "bestParam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
